{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu là gì?\n",
    "\n",
    "- Là bước đầu tiên quan trọng trong việc phân tích dữ liệu. Nó cho phép bạn chuyển đổi dữ liệu thô thành định dạng dễ hiểu và có thể sử dụng để phân tích. Đây là một quy trình toàn diện đảm bảo dữ liệu được chuẩn bị và sẵn sàng cho các giai đoạn khám phá, lập mô hình và diễn giải tiếp theo.\n",
    "\n",
    "Tiền xử lý để làm gì?\n",
    "- Dữ liệu thô thường không hoàn hảo: có thể chứa giá trị thiếu, nhiễu, hoặc không nhất quán\n",
    "- Tăng độ chính xác: giúp mô hình học máy hoạt động tốt hơn\n",
    "- Chuẩn hóa định dạng: dữ liệu có thể đến từ nguồn khác nhau với cấu trúc khác nhau\n",
    "- Giảm độ phức tạp: làm sạch dữ liệu để tăng tốc quá trình xử lý và phân tích\n",
    "- Các mô hình ML chỉ làm việc với dữ liệu ma trận hoặc vector\n",
    "- Dễ lưu trữ/ truy vấn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các bước tiền xử lý dữ liệu\n",
    "\n",
    "1. Thu thập dữ liệu\n",
    "- Tập hợp dữ liệu từ các nguồn khác nhau: cơ sở dữ liệu, API, tập tin CSV, logs, v.v\n",
    "- Xác định các yếu tố ảnh hưởng đển chất lượng dữ liệu, ví dụ: độ đầy đủ, tính tin cậy\n",
    "\n",
    "2. Xử lý giá trị thiếu\n",
    "- Loại bỏ các hàng hoặc cột có nhiều giá trị thiếu\n",
    "- Thay thế giá trị thiếu bằng:\n",
    "    + Trung bình (Mean): thường dùng cho dữ liệu số\n",
    "    + Trung vị (Median): Tốt hơn trong trường hợp dữ liệu bị lệch\n",
    "    + Mode: áp dụng cho dữ liệu phân loại\n",
    "    + Giá trị cố định hoặc dự đoán bằng các thuật toán\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Xử lý dữ liệu không hợp lệ\n",
    "- Loại bỏ các giá trị bất thường (outliers) hoặc nhiễu\n",
    "- Chuyển đổi định dạng (ví dụ: đổi ngày tháng từ định dạng text sang datetime)\n",
    "\n",
    "4. Chuẩn hóa\n",
    "- Normalization\n",
    "    + Đưa dữ liệu về khoảng giá trị [0, 1] hoặc [-1, 1]\n",
    "    + Công thức phổ biến:\n",
    "        $$\n",
    "        X_\\text{normalized} = \\frac{X - X_\\text{min}}{X_\\text{max} - X_\\text{min}}\n",
    "        $$\n",
    "- Standardization\n",
    "    + Chuyển dữ liệu về phân phối chuẩn (mean = 0, standard deviation = 1)\n",
    "    + Công thức:\n",
    "    $$\n",
    "        Z = \\frac{X - \\mu}{\\sigma}\n",
    "    $$\n",
    "    Trong đó $\\mu$ là giá trị trung bình, $\\sigma$ là độ lệch chuẩn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name        Age      Score\n",
      "0    A  25.000000  80.000000\n",
      "1    B  30.000000  95.000000\n",
      "2    C  31.666667  81.666667\n",
      "3    D  31.666667  70.000000\n",
      "4    E  40.000000  81.666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dữ liệu mẫu\n",
    "data = {'Name': ['A', 'B', 'C', 'D', 'E'],\n",
    "        'Age': [25, 30, 120, -5, 40],  # 120 và -5 là không hợp lệ\n",
    "        'Score': [80, 95, np.nan, 70, 200]}  # np.nan và 200 là không hợp lệ\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Xử lý giá trị không hợp lệ trong cột 'Age' (phạm vi hợp lệ: 0-100)\n",
    "df['Age'] = df['Age'].apply(lambda x: np.nan if x < 0 or x > 100 else x)\n",
    "\n",
    "# 2. Xử lý giá trị thiếu hoặc không hợp lệ trong cột 'Score' (giới hạn max = 100)\n",
    "df['Score'] = df['Score'].apply(lambda x: np.nan if x > 100 else x)\n",
    "\n",
    "# 3. Điền giá trị thiếu bằng trung bình\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Score'] = df['Score'].fillna(df['Score'].mean())\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name       Age     Score\n",
      "0    A  0.000000  0.400000\n",
      "1    B  0.333333  1.000000\n",
      "2    C  0.444444  0.466667\n",
      "3    D  0.444444  0.000000\n",
      "4    E  1.000000  0.466667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name           Age         Score\n",
      "0    A -1.380131e+00 -2.094270e-01\n",
      "1    B -3.450328e-01  1.675416e+00\n",
      "2    C  1.723785e-16  3.487659e-16\n",
      "3    D  1.723785e-16 -1.465989e+00\n",
      "4    E  1.725164e+00  3.487659e-16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'Score']] = scaler.fit_transform(df[['Age', 'Score']])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Biến đổi dữ liệu (Feature Transformation)\n",
    "- Log Transformation: Dùng để giảm ảnh hưởng của dữ liệu lệch\n",
    "- Square Root Transformation\n",
    "- Power Transformation\n",
    "- Scaling and Normalization: Đưa dữ liệu về một phạm vi cố định hoặc phân phối chuẩn.\n",
    "- Encoding dữ liệu phân loại:\n",
    "    + One-hot encoding: biến đổi dữ liệu phân loại thành dạng nhị phân\n",
    "    + Label encoding: Gán nhãn số cho các giá trị phân loại.\n",
    "    + Binary Encoding\n",
    "        Mỗi giá trị phân loại được chuyển đổi thành một số nguyên duy nhất.\n",
    "        Số nguyên này sau đó được chuyển thành dạng nhị phân.\n",
    "        Các chữ số nhị phân được lưu trong các cột riêng biệt (mỗi chữ số là một cột).\n",
    "    + BaseN Encoding: giống binary encoding nhưng với nhiều cơ số khác tùy ý\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Log_Value\n",
      "0      1   0.693147\n",
      "1     10   2.397895\n",
      "2    100   4.615121\n",
      "3   1000   6.908755\n",
      "4  10000   9.210440\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dữ liệu mẫu\n",
    "data = {'Value': [1, 10, 100, 1000, 10000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Biến đổi log\n",
    "df['Log_Value'] = np.log1p(df['Value'])  # log(1 + X)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Square Root Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Log_Value  Sqrt_Value\n",
      "0      1   0.693147    1.000000\n",
      "1     10   2.397895    3.162278\n",
      "2    100   4.615121   10.000000\n",
      "3   1000   6.908755   31.622777\n",
      "4  10000   9.210440  100.000000\n"
     ]
    }
   ],
   "source": [
    "# Biến đổi căn bậc hai\n",
    "df['Sqrt_Value'] = np.sqrt(df['Value'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Transformation\n",
    "\n",
    "- Để khuếch đại ảnh hưởng của các giá trị lớn hơn\n",
    "- Chuyển đổi dữ liệu về phân phối chuẩn khi sử dụng Box-Cox hoặc Yeo-Johnson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Log_Value  Sqrt_Value  Squared_Value\n",
      "0      1   0.693147    1.000000              1\n",
      "1     10   2.397895    3.162278            100\n",
      "2    100   4.615121   10.000000          10000\n",
      "3   1000   6.908755   31.622777        1000000\n",
      "4  10000   9.210440  100.000000      100000000\n"
     ]
    }
   ],
   "source": [
    "# Biến đổi bình phương\n",
    "df['Squared_Value'] = df['Value'] ** 2\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Log_Value  Sqrt_Value  Squared_Value  Min_Max_Scaled\n",
      "0      1   0.693147    1.000000              1        0.000000\n",
      "1     10   2.397895    3.162278            100        0.000900\n",
      "2    100   4.615121   10.000000          10000        0.009901\n",
      "3   1000   6.908755   31.622777        1000000        0.099910\n",
      "4  10000   9.210440  100.000000      100000000        1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['Min_Max_Scaled'] = scaler.fit_transform(df[['Value']])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Log_Value  Sqrt_Value  Squared_Value  Min_Max_Scaled   Z_Score\n",
      "0      1   0.693147    1.000000              1        0.000000 -0.568533\n",
      "1     10   2.397895    3.162278            100        0.000900 -0.566229\n",
      "2    100   4.615121   10.000000          10000        0.009901 -0.543193\n",
      "3   1000   6.908755   31.622777        1000000        0.099910 -0.312831\n",
      "4  10000   9.210440  100.000000      100000000        1.000000  1.990787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['Z_Score'] = scaler.fit_transform(df[['Value']])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding và Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category_bird  Category_cat  Category_dog\n",
      "0            0.0           1.0           0.0\n",
      "1            0.0           0.0           1.0\n",
      "2            1.0           0.0           0.0\n",
      "3            0.0           0.0           1.0\n",
      "4            0.0           1.0           0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categories = ['cat', 'dog', 'bird']\n",
    "data = pd.DataFrame({'Category': ['cat', 'dog', 'bird', 'dog', 'cat']})\n",
    "encoder = OneHotEncoder()\n",
    "encoded = encoder.fit_transform(data[['Category']])\n",
    "encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(['Category']))\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Rút gọn dữ liệu (Dimensionality Reduction)\n",
    "- PCA (Principal Component Analysis): giảm số chiều nhưng vẫn giữ lại thông tin quan trọng\n",
    "    - cách hoạt động:\n",
    "        + Chuẩn hóa dữ liệu về trung bình = 0.\n",
    "        + Tính ma trận hiệp phương sai (CovarianceMatrix).\n",
    "        + Tính các giá trị riêng (eigenvalues) và vector riêng (eigenvectors).\n",
    "        + Chọn các vector riêng tương ứng với các giá trị riêng lớn nhất để tạo thành không gian mới.\n",
    "\n",
    "\n",
    "- Lựa chọn dặc trung (Feature Selection): loại bỏ các đặc trung ít quan trọng\n",
    "    + Mục đích: Chọn một tập con các đặc trưng quan trọng nhất trong tập dữ liệu, thay vì sử dụng toàn bộ.\n",
    "\n",
    "- Tác dụng:\n",
    "    + Tăng hiệu quả tính toán: ít đặc trưng hơn giúp thuật toán chạy nhanh hơn\n",
    "    + Giảm nhiễu: loại bỏ các đặc trưng không quan trọng hoặc dư thừa, giúp cải thiện hiệu suất của mô hình\n",
    "    + Trực quan hóa: giảm dữ liệu xuống 2 hoặc 3 chiều để có thể trực quan hóa\n",
    "\n",
    "7. Chia tách dữ liệu\n",
    "Chia dữ liệu thành:\n",
    "    - Tập huấn luyện: 70-80% dữ liệu\n",
    "    - Tập kiểm tra: 20-30% dữ liệu\n",
    "Đảm bảo tính ngẫu nhiên hoặc phân tầng khi tách dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các công cụ hỗ trợ tiền xử lý dữ liệu\n",
    "\n",
    "- Python\n",
    "\n",
    "- R\n",
    "\n",
    "- SQL\n",
    "\n",
    "- Excel/GG sheets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý:\n",
    "- Hiểu rõ dữ liệu trước khi xử lý: Kiểm tra phân phối, giá trị ngoại lệ, kiểu dữ liệu\n",
    "\n",
    "- Luôn lưu trữ dữ liệu gốc để đối chiếu khi cần\n",
    "\n",
    "- Tránh overfitting khi tiền xử lý: không áp dụng thông tin từ tập kiểm tra vào tập huấn luyện\n",
    "\n",
    "- Ghi nhận các bước tiền xử lý để đảm bảo tái tạo dữ liệu khi cần\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham khảo: https://neptune.ai/blog/data-preprocessing-guide\n",
    "https://www.thienhang.com/2024/04/data-preprocessing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
